{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-25T19:24:50.988198Z",
     "start_time": "2026-01-25T19:24:50.981695Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import NMF\n",
    "# TODO START"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Imputer**\n",
    "\n",
    "* –î–ª—è –∑–∞–º–µ–Ω—ã `–ø—Ä–æ–ø—É—Å–∫–æ–≤` –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö `feat_num` –∏ `feat_cat` –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:\n",
    "    * `feat_num` - `strategy=\"mean\"`\n",
    "    * `feat_cat` - `strategy=\"most_frequent\"`\n",
    "        * \n",
    "* strategy=\"mean\" ‚Äî –∑–∞–ø–æ–ª–Ω—è—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ —Å—Ä–µ–¥–Ω–∏–º –ø–æ –∫–æ–ª–æ–Ω–∫–µ\n",
    "\n",
    "* strategy=\"median\" ‚Äî –∑–∞–ø–æ–ª–Ω—è—Ç—å –º–µ–¥–∏–∞–Ω–æ–π\n",
    "\n",
    "* strategy=\"most_frequent\" ‚Äî –∑–∞–ø–æ–ª–Ω—è—Ç—å —Å–∞–º—ã–º —á–∞—Å—Ç—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–º–æ–¥–∞)\n",
    "\n",
    "* strategy=\"constant\" ‚Äî –∑–∞–ø–æ–ª–Ω—è—Ç—å –∫–æ–Ω—Å—Ç–∞–Ω—Ç–æ–π (fill_value=...)"
   ],
   "id": "4925de15e2a1cd50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T15:01:41.389679Z",
     "start_time": "2025-09-02T15:01:41.363251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# –ó–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é SimpleImputer\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [pd.NA, \"F\", \"W\", \"F\", \"W\"],   # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π\n",
    "    \"B\": [20, None, 30, 40, 50],         # —á–∏—Å–ª–æ–≤–æ–π\n",
    "    \"C\": [300, 200, 300, None, pd.NA]    # —á–∏—Å–ª–æ–≤–æ–π (—Å pd.NA)\n",
    "})\n",
    "\n",
    "# 1) –ó–∞–º–µ–Ω—è–µ–º pd.NA -> np.nan\n",
    "df = df.replace({pd.NA: np.nan})\n",
    "\n",
    "print('–ó–∞–º–µ–Ω—è–µ–º pd.NA –Ω–∞ np.nan : \\n', df)\n",
    "\n",
    "# TODO –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –∫–æ–ª–æ–Ω–æ–∫\n",
    "# 2) –ò–º–ø—É—Ç–∞—Ü–∏—è: mean –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö, most_frequent –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö\n",
    "cat_cols = [\"A\"]\n",
    "num_cols = [\"B\", \"C\"]\n",
    "\n",
    "# TODO 1-–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", SimpleImputer(strategy=\"mean\"), num_cols),\n",
    "#         (\"cat\", SimpleImputer(strategy=\"most_frequent\"), cat_cols)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# TODO 2-–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "# –ò–º–ø—É—Ç–µ—Ä—ã\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_imputer, num_cols),\n",
    "        (\"cat\", cat_imputer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# TODO –æ–±—Ä–∞—Ç–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º –≤ DF cat –∏ num –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "result = preprocessor.fit_transform(df)\n",
    "df_filled = pd.DataFrame(result, columns=num_cols + cat_cols)\n",
    "\n",
    "print(result)\n",
    "\n"
   ],
   "id": "6a204aa905afd360",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–º–µ–Ω—è–µ–º pd.NA –Ω–∞ np.nan : \n",
      "      A  B  C\n",
      "0    a  1  4\n",
      "1    a  2  5\n",
      "2  NaN  3  6\n",
      "[[1.0 4.0 'a']\n",
      " [2.0 5.0 'a']\n",
      " [3.0 6.0 'a']]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**ColumnTransformer ( SimpleImputer() –∏ get_dummies()) - –≤–º–µ—Å—Ç–µ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç**"
   ],
   "id": "87fb8ca1a5caf7a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**–ü—Ä–∞–≤–∏–ª–∞**\n",
    "\n",
    "* –≤ ColumnTransformer –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ:\n",
    "    * –≤—Å–µ —Å–∫–æ–±–∫–∏ ColumnTransformer `( [ ( –∏–º—è, —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ç–æ—Ä, —Å—Ç–æ–ª–±—Ü—ã ) ] )`\n",
    "    * —Ç—Ä–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ `–∏–º—è, —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ç–æ—Ä, —Å—Ç–æ–ª–±—Ü—ã` –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å `–æ–¥–Ω–∏–º –æ–±—ä–µ–∫—Ç–æ–º`"
   ],
   "id": "375316c1598878d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "89d5bd1f56091209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T15:03:46.548437Z",
     "start_time": "2025-09-02T15:03:46.502404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame({\n",
    "    \"A\": [pd.NA, \"F\", \"W\", \"F\", \"W\"],   # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π\n",
    "    \"B\": [20, None, 30, 40, 50],         # —á–∏—Å–ª–æ–≤–æ–π\n",
    "    \"C\": [300, 200, 300, None, pd.NA]    # —á–∏—Å–ª–æ–≤–æ–π (—Å pd.NA)\n",
    "})\n",
    "\n",
    "print('–ò—Å—Ö–æ–¥–Ω—ã–π DF : \\n', df, '\\n')\n",
    "\n",
    "# TODO –ó–∞–º–µ–Ω—è–µ–º pd.NA -> np.nan\n",
    "data = df.replace({pd.NA: np.nan})\n",
    "\n",
    "name_col_odj = data.select_dtypes(include=['object', 'category']).columns\n",
    "name_col_int = data.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# TODO –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ç–æ—Ä—ã –¥–ª—è catfeat –∏ numfeat\n",
    "ohe_obj = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "imput_obj = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "scaler_int =StandardScaler()\n",
    "imput_int = SimpleImputer(strategy='mean')\n",
    "\n",
    "# TODO pipeline –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ catfeat –∏ numfeat\n",
    "pipe_obj = make_pipeline(imput_obj,ohe_obj)\n",
    "pipe_int = make_pipeline(imput_int, scaler_int)\n",
    "\n",
    "\n",
    "# TODO SimpleImputer –∏ get_dummies –ù–µ –†–∞–±–æ—Ç–∞–µ—Ç\n",
    "# pipe_obj = make_pipeline(SimpleImputer(strategy='most_frequent'), pd.get_dummies(data=data['A']).astype(int))\n",
    "\n",
    "\n",
    "\n",
    "data_trsf_obj = ColumnTransformer([('object', pipe_obj, name_col_odj)])\n",
    "data_trsf_int = ColumnTransformer([('numeric', pipe_int, name_col_int)])\n",
    "\n",
    "\n",
    "# TODO –ò–º–µ–Ω–∞ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ catfeat –ø–æ—Å–ª–µ –û–ù–ï –∏ numfeat –±–µ—Ä—ë–º –∏–∑ ColumnTransformer\n",
    "data_obj = data_trsf_obj.fit_transform(data)\n",
    "print('–ò–º–µ–Ω–∞ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –û–ù–ï : \\n', data_trsf_obj.get_feature_names_out(), '\\n')\n",
    "\n",
    "data_int = data_trsf_int.fit_transform(data)\n",
    "print('–ò–º–µ–Ω–∞ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ int : \\n', data_trsf_int.get_feature_names_out(), '\\n')\n",
    "\n",
    "df_obj = pd.DataFrame(data_obj, columns=[data_trsf_obj.get_feature_names_out()])\n",
    "df_int = pd.DataFrame(data_int, columns=[data_trsf_int.get_feature_names_out()])\n",
    "\n",
    "data_df = pd.concat([df_int, df_obj], axis=1)\n",
    "\n",
    "print('–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π DF : ')\n",
    "data_df"
   ],
   "id": "2f2712bf3a7a5114",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å—Ö–æ–¥–Ω—ã–π DF : \n",
      "       A  B  C\n",
      "0     a  1  4\n",
      "1     a  2  5\n",
      "2  <NA>  3  6 \n",
      "\n",
      "–ò–º–µ–Ω–∞ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –û–ù–ï : \n",
      " ['object__A_a'] \n",
      "\n",
      "–ò–º–µ–Ω–∞ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ int : \n",
      " ['numeric__B' 'numeric__C'] \n",
      "\n",
      "–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π DF : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  numeric__B numeric__C object__A_a\n",
       "0  -1.224745  -1.224745         1.0\n",
       "1   0.000000   0.000000         1.0\n",
       "2   1.224745   1.224745         1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>numeric__B</th>\n",
       "      <th>numeric__C</th>\n",
       "      <th>object__A_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**pipline DF -> –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è  -> LogReg-–º–æ–¥–µ–ª—å**\n",
    "\n",
    "* `C=10` - `–æ–±—Ä–∞—Ç–Ω–∞—è —Å–∏–ª–∞` —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏:\n",
    "    * –ß–µ–º `–º–µ–Ω—å—à–µ C`, —Ç–µ–º `—Å–∏–ª—å–Ω–µ–µ` —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è `(–±–æ–ª—å—à–µ —à—Ç—Ä–∞—Ñ)`.\n",
    "    * –ß–µ–º `–±–æ–ª—å—à–µ C`, —Ç–µ–º `–º–µ–Ω—å—à–µ` —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è.\n"
   ],
   "id": "e447035ed213b24e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T11:27:44.849711Z",
     "start_time": "2025-08-25T11:27:44.824054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, n_classes=2, n_clusters_per_class=1 , random_state=42)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# C = 1 / Œª (–æ–±—Ä–∞—Ç–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏).\n",
    "pipe_lg = make_pipeline(StandardScaler(), LogisticRegression(C=10))\n",
    "\n",
    "pipe_lg.fit(X_train, y_train)\n",
    "y_pred = pipe_lg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1-score: \", f1_score(y_test, y_pred, average=\"macro\"), '\\n')"
   ],
   "id": "c7264c0f31bbf2f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4) (1000,)\n",
      "Accuracy:  0.9\n",
      "Precision:  0.9001600640256102\n",
      "Recall:  0.9\n",
      "F1-score:  0.8999899989999 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "12a45a356fa3b576"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1\n",
    "\n",
    "**remainder**\n",
    "   * `remainder='passthrough'` - –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å—Ç–æ–ª–±—Ü—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å\n",
    "   * `remainder='drop'` - –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å—Ç–æ–ª–±—Ü—ã —É–¥–∞–ª–∏—Ç—å\n",
    "                       "
   ],
   "id": "abc392fc2451ba3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T16:47:04.411704Z",
     "start_time": "2025-08-25T16:47:04.396241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X = pd.DataFrame(\n",
    "    {'city': ['London', 'London', 'Paris', 'Sallisaw'],\n",
    "     'title': [\"His Last Bow\", \"How Watson Learned the Trick\",\n",
    "               \"A Moveable Feast\", \"The Grapes of Wrath\"],\n",
    "     'expert_rating': [500, 300, 400, 500],\n",
    "     'user_rating': [0.4, 0.5, 0.4, 0.3]})\n",
    "\n",
    "column_trans = ColumnTransformer(\n",
    "    [('city_category', OneHotEncoder(dtype='int'),['city']),\n",
    "     ('title_bow', CountVectorizer(), 'title')],\n",
    "    remainder='passthrough')\n",
    "\n",
    "column_trans.fit_transform(X)"
   ],
   "id": "dcfaebcf66d09c37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.e+00, 0.e+00, 0.e+00, 1.e+00, 0.e+00, 0.e+00, 1.e+00, 0.e+00,\n",
       "        1.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00,\n",
       "        5.e+02, 4.e-01],\n",
       "       [1.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 1.e+00,\n",
       "        0.e+00, 1.e+00, 0.e+00, 0.e+00, 1.e+00, 1.e+00, 1.e+00, 0.e+00,\n",
       "        3.e+02, 5.e-01],\n",
       "       [0.e+00, 1.e+00, 0.e+00, 0.e+00, 1.e+00, 0.e+00, 0.e+00, 0.e+00,\n",
       "        0.e+00, 0.e+00, 1.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00,\n",
       "        4.e+02, 4.e-01],\n",
       "       [0.e+00, 0.e+00, 1.e+00, 0.e+00, 0.e+00, 1.e+00, 0.e+00, 0.e+00,\n",
       "        0.e+00, 0.e+00, 0.e+00, 1.e+00, 1.e+00, 0.e+00, 0.e+00, 1.e+00,\n",
       "        5.e+02, 3.e-01]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2\n",
    "\n",
    "* `remainder=MinMaxScaler()` - –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å—Ç–æ–ª–±—Ü—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å  "
   ],
   "id": "6ce7e08987a47c21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T16:51:32.149792Z",
     "start_time": "2025-08-25T16:51:32.131135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# –î–∞–Ω–Ω—ã–µ\n",
    "df = pd.DataFrame({\n",
    "    'age': [20, 30, 40],\n",
    "    'salary': [2000, 3000, 4000],\n",
    "    'city': ['Moscow', 'SPb', 'Kazan']\n",
    "})\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age']),       # —Ç–æ–ª—å–∫–æ age —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º\n",
    "        ('cat', OneHotEncoder(), ['city'])        # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–¥–∏—Ä—É–µ–º\n",
    "    ],\n",
    "    remainder=MinMaxScaler()  # –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Å—Ç–æ–ª–±–µ—Ü (salary) –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º\n",
    ")\n",
    "\n",
    "result = ct.fit_transform(df)\n",
    "print(result)\n"
   ],
   "id": "617a7747a0b7e7c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.22474487  0.          1.          0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.5       ]\n",
      " [ 1.22474487  1.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# –í–∞—Ä–∏–∞–Ω—Ç 1\n",
    "# CountVectorizer ‚Üí `—Å–æ–∑–¥–∞—ë—Ç —Å–ª–æ–≤–∞—Ä—å –∏ —Å—á–∏—Ç–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã.`\n",
    "\n",
    "# TfidfTransformer ‚Üí `–ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç —ç—Ç–∏ —á–∞—Å—Ç–æ—Ç—ã –≤ –≤–µ—Å–∞, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —à—Ç—Ä–∞—Ñ`\n",
    "\n",
    "**CountVectorizer + TfidfTransformer**\n",
    "\n",
    "*   –ë–µ—Ä—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Ç–µ–∫—Å—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `—Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫`).\n",
    "\n",
    "*   –°—Ç—Ä–æ–∏–º `—Å–ª–æ–≤–∞—Ä—å` –≤—Å–µ—Ö `—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö` —Å–ª–æ–≤.\n",
    "\n",
    "*   –î–ª—è –∫–∞–∂–¥–æ–≥–æ `—Ç–µ–∫—Å—Ç–∞`(`—Å—Ç—Ä–æ–∫–∏`) —Å—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è.\n",
    "\n",
    "*   –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ–ª—É—á–∞–µ–º —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É —Ä–∞–∑–º–µ—Ä–∞ (`—á–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤(—Å—Ç—Ä–æ–∫) `√ó `—á–∏—Å–ª–æ —Å–ª–æ–≤(—Ç–æ–∫–µ–Ω–æ–≤)`)."
   ],
   "id": "1a6a41d18419d840"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T11:06:27.856759Z",
     "start_time": "2026-01-21T11:06:27.837218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [\n",
    "    \"–∫–æ—Ç –ª—é–±–∏—Ç –º–æ–ª–æ–∫–æ\",\n",
    "    \"—Å–æ–±–∞–∫–∞ –ª—é–±–∏—Ç –∫–æ—Å—Ç—å\",\n",
    "    \"–∫–æ—Ç –∏ —Å–æ–±–∞–∫–∞ –¥—Ä—É–∑—å—è\"\n",
    "]\n",
    "\n",
    "# docs = [\n",
    "#     \n",
    "#         \"Human machine interface for lab abc computer applications\",\n",
    "#         \"A survey of user opinion of computer system response time\",\n",
    "#         \"The EPS user interface management system\",\n",
    "#         \"System and human system engineering testing of EPS\",\n",
    "#         \"Relation of user perceived response time to error measurement\",\n",
    "#         \"The generation of random binary unordered trees\",\n",
    "#         \"The intersection graph of paths in trees\",\n",
    "#         \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "#         \"Graph minors A survey\",\n",
    "#     \n",
    "# ]\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_vect = count_vect.fit_transform(docs)\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã: {X_vect.shape}  # {X_vect.shape[0]} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ √ó {X_vect.shape[1]} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: \\n\", X_vect.shape, '\\n')\n",
    "print(X_vect.toarray())\n",
    "\n",
    "tfidf_transform = TfidfTransformer()\n",
    "\n",
    "X_word = tfidf_transform.fit_transform(X_vect)\n",
    "\n",
    "print('X_word - CountVectorizer + TfidfTransformer, —Ä–∞–∑—Ä–µ–∂—ë–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (sparse matrix) : \\n', X_word, '\\n')\n"
   ],
   "id": "6149145993b8d10d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã: (3, 6)  # 3 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ √ó 6 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: \n",
      " (3, 6) \n",
      "\n",
      "[[0 0 1 1 1 0]\n",
      " [0 1 0 1 0 1]\n",
      " [1 0 1 0 0 1]]\n",
      "X_word - CountVectorizer + TfidfTransformer, —Ä–∞–∑—Ä–µ–∂—ë–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (sparse matrix) : \n",
      "   (0, 2)\t0.5178561161676974\n",
      "  (0, 3)\t0.5178561161676974\n",
      "  (0, 4)\t0.680918560398684\n",
      "  (1, 1)\t0.680918560398684\n",
      "  (1, 3)\t0.5178561161676974\n",
      "  (1, 5)\t0.5178561161676974\n",
      "  (2, 0)\t0.680918560398684\n",
      "  (2, 2)\t0.5178561161676974\n",
      "  (2, 5)\t0.5178561161676974 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# –í–∞—Ä–∏–∞–Ω—Ç 2",
   "id": "4a73b5d929d57622"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TfidfVectorizer  `‚Üí ¬´–≤—Å—ë –≤ –æ–¥–Ω–æ–º¬ª`",
   "id": "3070da58a19dc3b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**–î—É–±–ª–∏—Ä—É–µ–º–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤ - –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞**\n",
    "\n",
    "(1, 9)    0.3516654787271834\n",
    "\n",
    "* 1 ‚Äî –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å—Ç—Ä–æ–∫–∞, –Ω–∞—á–∏–Ω–∞—è —Å 0),\n",
    "\n",
    "* 9 ‚Äî –∏–Ω–¥–µ–∫—Å —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ (–∫–æ–ª–æ–Ω–∫–∞),\n",
    "\n",
    "* 0.3516... ‚Äî –≤–µ—Å TF-IDF –¥–ª—è —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞ –≤ —ç—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ.\n",
    "\n",
    "–ó–Ω–∞—á–µ–Ω–∏—è –ª–µ–∂–∞—Ç –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ 1:\n",
    "\n",
    "1 ‚Üí `—Ç–µ–∫—Å—Ç—ã –∏–¥–µ–Ω—Ç–∏—á–Ω—ã`,\n",
    "\n",
    "0 ‚Üí `—Ç–µ–∫—Å—Ç—ã –≤–æ–æ–±—â–µ –Ω–µ –ø–æ—Ö–æ–∂–∏.`"
   ],
   "id": "a4d7bad845861e3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:18:41.970346Z",
     "start_time": "2026-01-25T20:18:41.931431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# –î–æ–ø—É—Å—Ç–∏–º, —É –Ω–∞—Å –µ—Å—Ç—å –∫–ª–∞—Å—Å—ã —Ç–∏–∫–µ—Ç–æ–≤ (–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π)\n",
    "\n",
    "\n",
    "classes = [\n",
    "    \"–∫–æ—Ç –ª—é–±–∏—Ç –º–æ–ª–æ–∫–æ\",\n",
    "    \"—Å–æ–±–∞–∫–∞ –ª—é–±–∏—Ç –∫–æ—Å—Ç—å\",\n",
    "    \"–∫–æ—Ç –∏ —Å–æ–±–∞–∫–∞ –¥—Ä—É–∑—å—è\"\n",
    "]\n",
    "\n",
    "# classes = [\n",
    "#     \"–û—à–∏–±–∫–∞ –≤—Ö–æ–¥–∞\",\n",
    "#     \"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ —Å–∏—Å—Ç–µ–º—É\",\n",
    "#     \"–ù–µ –º–æ–≥—É –≤–æ–π—Ç–∏ –≤ –∞–∫–∫–∞—É–Ω—Ç\",\n",
    "#     \"–ü—Ä–æ–±–ª–µ–º–∞ —Å –æ–ø–ª–∞—Ç–æ–π\",\n",
    "#     \"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø–ª–∞—Ç–µ\",\n",
    "#     \"–°–±—Ä–æ—Å –ø–∞—Ä–æ–ª—è\",\n",
    "#     \"–ü—Ä–æ–±–ª–µ–º–∞ –ø–∞—Ä–æ–ª—è\",\n",
    "#     \"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞—Ä–æ–ª—è\"\n",
    "# ]\n",
    "\n",
    "# classes = [\n",
    "#     \n",
    "#         \"Human machine interface for lab abc computer applications\",\n",
    "#         \"A survey of user opinion of computer system response time\",\n",
    "#         \"The EPS user interface management system\",\n",
    "#         \"System and human system engineering testing of EPS\",\n",
    "#         \"Relation of user perceived response time to error measurement\",\n",
    "#         \"The generation of random binary unordered trees\",\n",
    "#         \"The intersection graph of paths in trees\",\n",
    "#         \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "#         \"Graph minors A survey\",\n",
    "#     \n",
    "# ]\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'class_name': classes})\n",
    "\n",
    "print('–ò—Å—Ö–æ–¥–Ω—ã–π df : \\n', df, '\\n')\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (TF-IDF)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['class_name'])\n",
    "\n",
    "print('X - vectorizer, sparse matrix >>> –≤–µ—Å–∞ —Å–ª–æ–≤ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º : \\n', X, '\\n')\n",
    "\n",
    "feature_name = vectorizer.get_feature_names_out(X)\n",
    "\n",
    "print('get_feature_names_out -> –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –°–ª–æ–≤–∞ : \\n', feature_name)\n",
    "\n",
    "print('–°–ª–æ–≤–∞—Ä—å tf-idf : \\n', vectorizer.vocabulary_, '\\n')\n",
    "\n",
    "\n",
    "# TODO –∫–æ—Å–∏–Ω—É—Å–Ω—ã–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ - –ü–æ—Å–ª–µ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "# 2Ô∏è‚É£ –°—á–∏—Ç–∞–µ–º –ø–æ–ø–∞—Ä–Ω—ã–µ –∫–æ—Å–∏–Ω—É—Å–Ω—ã–µ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "similarity = np.round(cosine_similarity(X), 4)\n",
    "\n",
    "print('–ú–∞—Ç—Ä–∏—Ü–∞ numpy –∫–æ—Å–∏–Ω—É—Å–Ω—ã–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: \\n', similarity, '\\n')\n",
    "\n",
    "# 3Ô∏è‚É£ –ü–µ—Ä–µ–≤–µ–¥—ë–º –≤ DataFrame –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "sim_df = pd.DataFrame(similarity, index=classes, columns=classes)\n",
    "\n",
    "print('–∫–æ—Å–∏–Ω—É—Å–Ω—ã–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ : \\n', sim_df, '\\n')\n",
    "\n",
    "# TODO cos –ü–æ–¥–æ–±–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ python —Ü–∏–∫–ª\n",
    "# 4Ô∏è‚É£ –ù–∞–π–¥—ë–º –ø–∞—Ä—ã –∫–ª–∞—Å—Å–æ–≤, –ø–æ—Ö–æ–∂–∏—Ö —Å–∏–ª—å–Ω–µ–µ –ø–æ—Ä–æ–≥–∞\n",
    "threshold = 0.3\n",
    "similar_pairs = []\n",
    "\n",
    "for i in range(len(sim_df)):  # –°—Ç—Ä–æ–∫–∏   \n",
    "    for j in range(i+1, len(sim_df)):  # –°—Ç–æ–ª–±—Ü—ã, üëâ –∏–Ω–¥–µ–∫—Å –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º i+1, –æ–±—Ö–æ–¥–∏–º –¥–∏–∞–≥–æ–Ω–∞–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º 1 \n",
    "        if sim_df.iloc[i, j] > threshold:\n",
    "            similar_pairs.append((\n",
    "                df['class_name'][i],\n",
    "                df['class_name'][j],\n",
    "                round(sim_df.iloc[i, j], 3)\n",
    "            ))\n",
    "\n",
    "df = pd.DataFrame(similar_pairs, columns=['class_1', 'class_2', 'similarity'])\n",
    "print('–î—É–±–ª–∏—Ä—É–µ–º—ã–µ –∫–ª–∞—Å—Å—ã :\\n', df)\n"
   ],
   "id": "13d5371c34ef2d1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å—Ö–æ–¥–Ω—ã–π df : \n",
      "             class_name\n",
      "0     –∫–æ—Ç –ª—é–±–∏—Ç –º–æ–ª–æ–∫–æ\n",
      "1   —Å–æ–±–∞–∫–∞ –ª—é–±–∏—Ç –∫–æ—Å—Ç—å\n",
      "2  –∫–æ—Ç –∏ —Å–æ–±–∞–∫–∞ –¥—Ä—É–∑—å—è \n",
      "\n",
      "X - vectorizer, sparse matrix >>> –≤–µ—Å–∞ —Å–ª–æ–≤ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º : \n",
      "   (0, 2)\t0.5178561161676974\n",
      "  (0, 3)\t0.5178561161676974\n",
      "  (0, 4)\t0.680918560398684\n",
      "  (1, 3)\t0.5178561161676974\n",
      "  (1, 5)\t0.5178561161676974\n",
      "  (1, 1)\t0.680918560398684\n",
      "  (2, 2)\t0.5178561161676974\n",
      "  (2, 5)\t0.5178561161676974\n",
      "  (2, 0)\t0.680918560398684 \n",
      "\n",
      "get_feature_names_out -> –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –°–ª–æ–≤–∞ : \n",
      " ['–¥—Ä—É–∑—å—è' '–∫–æ—Å—Ç—å' '–∫–æ—Ç' '–ª—é–±–∏—Ç' '–º–æ–ª–æ–∫–æ' '—Å–æ–±–∞–∫–∞']\n",
      "–°–ª–æ–≤–∞—Ä—å tf-idf : \n",
      " {'–∫–æ—Ç': 2, '–ª—é–±–∏—Ç': 3, '–º–æ–ª–æ–∫–æ': 4, '—Å–æ–±–∞–∫–∞': 5, '–∫–æ—Å—Ç—å': 1, '–¥—Ä—É–∑—å—è': 0} \n",
      "\n",
      "–ú–∞—Ç—Ä–∏—Ü–∞ numpy –∫–æ—Å–∏–Ω—É—Å–Ω—ã–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: \n",
      " [[1.     0.2682 0.2682]\n",
      " [0.2682 1.     0.2682]\n",
      " [0.2682 0.2682 1.    ]] \n",
      "\n",
      "–∫–æ—Å–∏–Ω—É—Å–Ω—ã–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ : \n",
      "                      –∫–æ—Ç –ª—é–±–∏—Ç –º–æ–ª–æ–∫–æ  —Å–æ–±–∞–∫–∞ –ª—é–±–∏—Ç –∫–æ—Å—Ç—å  –∫–æ—Ç –∏ —Å–æ–±–∞–∫–∞ –¥—Ä—É–∑—å—è\n",
      "–∫–æ—Ç –ª—é–±–∏—Ç –º–æ–ª–æ–∫–æ               1.0000              0.2682               0.2682\n",
      "—Å–æ–±–∞–∫–∞ –ª—é–±–∏—Ç –∫–æ—Å—Ç—å             0.2682              1.0000               0.2682\n",
      "–∫–æ—Ç –∏ —Å–æ–±–∞–∫–∞ –¥—Ä—É–∑—å—è            0.2682              0.2682               1.0000 \n",
      "\n",
      "–î—É–±–ª–∏—Ä—É–µ–º—ã–µ –∫–ª–∞—Å—Å—ã :\n",
      " Empty DataFrame\n",
      "Columns: [class_1, class_2, similarity]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# –ü–æ–¥–æ–±–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ numpy - triu\n",
    "\n",
    "**–ö–ª—é—á–µ–≤–æ–µ - `—É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —á–µ—Ä–µ–∑ –æ–±—Ä–µ–∑–∞–Ω–∏–µ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–¥–æ–±–∏—è`**\n",
    "\n",
    "**–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—Å–µ–≥–¥–∞ 2 —Å—Ç–æ–ª–±—Ü–∞ - `–ü–æ—Ç–æ–º—É —á—Ç–æ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º 2 –¥–æ–∫—É–º–µ–Ω—Ç–∞`**"
   ],
   "id": "82e8ecabf13e53cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä k –≤ triu**\n",
    "\n",
    "| k     | –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç        |\n",
    "| ----- | --------------------- |\n",
    "| `k=0` | –≤–∫–ª—é—á–∞–µ—Ç—Å—è –¥–∏–∞–≥–æ–Ω–∞–ª—å  |\n",
    "| `k=1` | –¥–∏–∞–≥–æ–Ω–∞–ª—å –∏—Å–∫–ª—é—á–∞–µ—Ç—Å—è |\n",
    "| `k=2` | –µ—â—ë –≤—ã—à–µ              |\n"
   ],
   "id": "b9cacf70c2a7dd62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:18:51.013775Z",
     "start_time": "2026-01-25T20:18:50.998509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO k=1 –≤ np.triu –æ–±–Ω—É–ª—è–µ—Ç –≥–ª–∞–≤–Ω—É—é –¥–∏–∞–≥–æ–Ω–∞–ª—å\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "print('–ò—Å—Ö–æ–¥–Ω—ã–π –º–∞—Å—Å–∏–≤ –ø–æ–¥–æ–±–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ : \\n', similarity, '\\n')\n",
    "\n",
    "#  –£—Å–ª–æ–≤–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞\n",
    "cond = np.triu(similarity, k=1) > threshold\n",
    "\n",
    "#  –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É—Å–ª–æ–≤–∏—é\n",
    "x, y = np.where(cond)  \n",
    "print('–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É—Å–ª–æ–≤–∏—é \"> –ø–æ—Ä–æ–≥–∞\" : \\n', x, y, '\\n')\n",
    "\n",
    "#  –û–±—Ä–µ–∑–∫–∞ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏ –º–∞—Å—Å–∏–≤–∞ –ø–æ–¥–æ–±–∏—è + to df\n",
    "df = pd.DataFrame(np.triu(similarity, k=1), columns=classes, index=classes)\n",
    "\n",
    "# i - –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫, j - –∏–Ω–¥–µ–∫—Å —Å—Ç–æ–ª–±–æ–≤\n",
    "df_sim = pd.DataFrame([(df.index[i], df.columns[j], df.values[i, j]) for i, j in zip(x, y)], \n",
    "                      columns=['doc_similarity_1', 'doc_similarity_2', 'similarity'])\n",
    "\n",
    "df_sim"
   ],
   "id": "960871b09067ab48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å—Ö–æ–¥–Ω—ã–π –º–∞—Å—Å–∏–≤ –ø–æ–¥–æ–±–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ : \n",
      " [[1.     0.2682 0.2682]\n",
      " [0.2682 1.     0.2682]\n",
      " [0.2682 0.2682 1.    ]] \n",
      "\n",
      "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É—Å–ª–æ–≤–∏—é \"> –ø–æ—Ä–æ–≥–∞\" : \n",
      " [] [] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_similarity_1, doc_similarity_2, similarity]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_similarity_1</th>\n",
       "      <th>doc_similarity_2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# NMF\n",
    "** NMF - `X-–º–∞—Ç—Ä—Ü–∞ -> documents √ó topics -> topics √ó words`**\n",
    "\n",
    "** LDA - `word √ó topics -> topics √ó document` **\n"
   ],
   "id": "42e491cbcbf3277c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:26:42.403263Z",
     "start_time": "2026-01-25T20:26:42.387932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=2, random_state=42)\n",
    "W = nmf.fit_transform(X)   # documents √ó topics\n",
    "H = nmf.components_        # topics √ó words\n",
    "\n",
    "print(f'{W.shape[0]} –¥–æ–∫—É–º–µ–Ω—Ç–∞ √ó {W.shape[1]}  —Ç–µ–º—ã : \\n', W, '\\n')\n",
    "\n",
    "print(f'{H.shape[0]} –¢–µ–º(—ã) √ó {H.shape[1]} —Å–ª–æ–≤ : \\n', H )\n"
   ],
   "id": "8ba3d0cfc435ff2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 –¥–æ–∫—É–º–µ–Ω—Ç–∞ √ó 2  —Ç–µ–º—ã : \n",
      " [[5.10343691e-01 1.05536020e-04]\n",
      " [5.10487257e-01 0.00000000e+00]\n",
      " [0.00000000e+00 8.82373199e-01]] \n",
      "\n",
      "2 –¢–µ–º(—ã) √ó 6 —Å–ª–æ–≤ : \n",
      " [[0.00000000e+00 6.67117617e-01 5.07156785e-01 1.01457760e+00\n",
      "  6.66929994e-01 5.07299482e-01]\n",
      " [7.71689974e-01 0.00000000e+00 5.86925227e-01 9.87338634e-09\n",
      "  4.61618718e-05 5.86855023e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T20:19:14.543720Z",
     "start_time": "2026-01-25T20:19:14.531193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W\n",
    "# H"
   ],
   "id": "3be3aba76490671b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.10343691e-01, 1.05536020e-04],\n",
       "       [5.10487257e-01, 0.00000000e+00],\n",
       "       [0.00000000e+00, 8.82373199e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "363a9022937ec8a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
