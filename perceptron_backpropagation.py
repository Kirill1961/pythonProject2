import numpy as np


# TODO Прямое распространение сигнала
#  * 3 нейрона х 1 слой


# Входной сигнал (4 признака)
x = np.array([1.0, 0.5, -1.5, 2.0])

# Весовая матрица (3 нейрона, 4 входа)
W = np.array([
    [0.2, -0.4, 0.1, 0.5],
    [-0.3, 0.8, -0.6, 0.9],
    [0.7, -0.1, 0.3, -0.2]
])

# Смещения
b = np.array([0.1, -0.2, 0.05])

# TODO  Линейная комбинация + ReLU активация, @ - перемножение матриц/векторов
z = W @ x + b
a = np.maximum(0, z)  # ReLU

print("Выход слоя:", a)


# TODO backpropogation


# --- ДАННЫЕ ---
x = np.array([1.0, -2.0, 3.0, 0.5])  # вход (shape: 4,)
W = np.array([
    [0.2, -0.4, 0.1, 0.5],
    [-0.3, 0.8, -0.6, 0.9],
    [0.7, -0.1, 0.3, -0.2]
])  # shape: (3, 4)
b = np.array([0.1, -0.2, 0.05])  # смещение (shape: 3,)
y_true = np.array([1.0, 0.0, 0.5])  # целевой вектор

# TODO--- FORWARD PASS через ReLU ---
#  * z - вход в нейрон
#  * а - выход  нейрона
#  * np.maximum(0, z) - прямой проход через активацию
z = W @ x + b
a = np.maximum(0, z)  # ReLU

# --- ПОТЕРЯ (MSE) ---
# TODO  вектор, Среднеквадратичная ошибка
#  * a - выход нейрона
#  * y_true - истинное/наблюдаемое значение
#  * MSE - оценка качества модели, чем меньше тем лучше
loss = np.mean((a - y_true)**2)  # MSE
print("Loss:", round(loss, 4), '>>')

# TODO  --- BACKWARD PASS ---
#  * 1. вектор, Градиент по выходу ReLU - Локальный градиент
#  * (a - y_true) - ошибка на выходе
#  * len(y_true) - делим на длину y_true так как ищем среднеквадратичную ошибку
#  * dL_da - Локальный градиент
dL_da = 2 * (a - y_true) / len(y_true)  # dL/da
print(dL_da, '>>>>')

# TODO 2. Производная ReLU - потому производная, что это обратное распространение ошибки
#  * так как результат ReLU бинарный, то вычисление через булеву маску da_dz = (z > 0)
#  * вектор, da_dz - выход производной функции активации ReLU в обратном! направлении
da_dz = (z > 0).astype(float)
print(da_dz, z)


# TODO 3. вектор, dL_dz - коррекция результата прямого распространения
#  * dL_dz - выход ReLU в обратном направлении
dL_dz = dL_da * da_dz


# TODO 4. dL/dW = dL/dz * x.T
#  * dL/dW  матрица коэффициентов для коррекции весов
#  * n строк = n (x.T) -> вектор столбец
#  * m столбцов = m (dL_dz.reshape(-1, 1)) -> вектор строка
dL_dW = dL_dz.reshape(-1, 1) @ x.reshape(1, -1)
print(dL_dz.reshape(-1, 1), '<<')
print(x.reshape(1, -1), '<<<<')

# TODO 5. dL/db = dL/dz
dL_db = dL_dz

# print("\nГрадиент по W:\n", dL_dW)
# print("\nГрадиент по b:\n", dL_db)

